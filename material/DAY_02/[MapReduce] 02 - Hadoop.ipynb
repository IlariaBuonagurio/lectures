{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop\n",
    "(and Hadoop streaming)\n",
    "\n",
    "<center>\n",
    "<img src='http://www.opensourceforu.efytimes.com/wp-content/uploads/2012/03/hadoop-database-590x321.jpg'>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**MapReduce** is a completely different paradigm \n",
    "\n",
    "* Solving a certain subset of parallelizable problems \n",
    "    - around the bottleneck of ingesting input data from disk\n",
    "* Traditional parallelism brings the data to the computing machine\n",
    "    - Map/reduce does the opposite, it brings the compute to the data\n",
    "* Input data is not stored on a separate storage system\n",
    "* Data exists in little pieces \n",
    "    - and is permanently stored on each computing node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MapReduce is the programming paradigm that allows massive scalability across thousands of servers.\n",
    "\n",
    "Its open source server implementation is the *Hadoop* cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Also always keep in mind that ***HDFS*** is fundamental to Hadoop \n",
    "\n",
    "* it provides the data chunking distribution across compute elements \n",
    "* necessary for map/reduce applications to be efficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word count\n",
    "The '`Hello World`' for MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Among the simplest of full Hadoop jobs you can run\n",
    "\n",
    "<img src='http://www.glennklockwood.com/data-intensive/hadoop/wordcount-schematic.png'\n",
    "width='700'>\n",
    "<small>Reading ***Moby Dick*** </small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How it works\n",
    "* The **MAP step** will take the raw text and convert it to key/value pairs\n",
    "    - Each key is a word\n",
    "    - All keys (words) will have a value of 1\n",
    "\n",
    "\n",
    "* The **REDUCE step** will combine all duplicate keys \n",
    "    - By adding up their values (sum)\n",
    "    - Every key (word) has a value of 1 (Map)\n",
    "    - Output is reduced to a list of unique keys\n",
    "    - Each key’s value corresponding to key's (word's) count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center>\n",
    "<img src='http://disco.readthedocs.org/en/latest/_images/map_shuffle_reduce.png' width=800>\n",
    "</center>\n",
    "\n",
    "### Map function:\n",
    "processes data and generates a set of  intermediate key/value pairs.\n",
    "\n",
    "\n",
    "### Reduce function:\n",
    "merges all intermediate values  associated with the same intermediate key."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A WordCount example \n",
    "*(with Java)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Consider doing a word count of the following file using  MapReduce:\n",
    "```\n",
    "Hello World Bye World\n",
    "Hello Hadoop Goodbye Hadoop\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The map function reads in words one at a time outputs (“word”, 1) for each parsed input word\n",
    "\n",
    "```\n",
    "(Hello, 1)\n",
    "(World, 1)\n",
    "(Bye, 1)\n",
    "(World, 1)\n",
    "(Hello, 1)\n",
    "(Hadoop, 1)\n",
    "(Goodbye, 1)\n",
    "(Hadoop, 1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The shuffle phase between map and reduce creates a  list of values associated with each key\n",
    "```\n",
    "(Bye, (1))\n",
    "(Goodbye, (1))\n",
    "(Hadoop, (1, 1))\n",
    "(Hello, (1, 1))\n",
    "(World, (1, 1))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reduce function sums the numbers in the list for each  key and outputs (word, count) pairs\n",
    "```\n",
    "(Bye, 1)\n",
    "(Goodbye, 1)\n",
    "(Hadoop, 2)\n",
    "(Hello, 2)\n",
    "(World, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How can you do this with Java?\n",
    "(the Hadoop framework native language)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "``` Java\n",
    "// Imports\n",
    "package org.myorg;\n",
    "import java.io.IOException;\n",
    "import java.util.*;\n",
    "import org.apache.hadoop.*\n",
    "\n",
    "// Create JAVA class\n",
    "public class WordCount {\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "``` Java\n",
    "//Mapper function\n",
    "  public static class Map extends MapReduceBase implements Mapper<LongWritable, Text, Text, IntWritable> {\n",
    "    private final static IntWritable one = new IntWritable(1);\n",
    "    private Text word = new Text();\n",
    "\n",
    "    public void map(LongWritable key, Text value, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {\n",
    "      String line = value.toString();\n",
    "      StringTokenizer tokenizer = new StringTokenizer(line);\n",
    "      while (tokenizer.hasMoreTokens()) {\n",
    "        word.set(tokenizer.nextToken());\n",
    "        output.collect(word, one);\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "``` Java\n",
    "//Reducer function\n",
    "  public static class Reduce extends MapReduceBase implements Reducer<Text, IntWritable, Text, IntWritable> {\n",
    "    public void reduce(Text key, Iterator<IntWritable> values, OutputCollector<Text, IntWritable> output, Reporter reporter) throws IOException {\n",
    "      int sum = 0;\n",
    "      while (values.hasNext()) {\n",
    "        sum += values.next().get();\n",
    "      }\n",
    "      output.collect(key, new IntWritable(sum));\n",
    "    }\n",
    "  }\n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<small>\n",
    "``` Java\n",
    "//Main function\n",
    "  public static void main(String[] args) throws Exception {\n",
    "    JobConf conf = new JobConf(WordCount.class);\n",
    "    conf.setJobName(\"wordcount\");\n",
    "\n",
    "    conf.setOutputKeyClass(Text.class);\n",
    "    conf.setOutputValueClass(IntWritable.class);\n",
    "\n",
    "    conf.setMapperClass(Map.class);\n",
    "    conf.setCombinerClass(Reduce.class);\n",
    "    conf.setReducerClass(Reduce.class);\n",
    "\n",
    "    conf.setInputFormat(TextInputFormat.class);\n",
    "    conf.setOutputFormat(TextOutputFormat.class);\n",
    "\n",
    "    FileInputFormat.setInputPaths(conf, new Path(args[0]));\n",
    "    FileOutputFormat.setOutputPath(conf, new Path(args[1]));\n",
    "\n",
    "    JobClient.runJob(conf);\n",
    "  }\n",
    "```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We can test the Java code here. *Live*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: HADOOP_EXAMPLES=/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar\n",
      "env: HADOOP_STREAMING=/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar\n"
     ]
    }
   ],
   "source": [
    "%env HADOOP_EXAMPLES /usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar\n",
    "%env HADOOP_STREAMING /usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/hadoop/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.6.0.jar'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env HADOOP_EXAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  aggregatewordcount: An Aggregate based map/reduce program that counts the words in the input files.\r\n",
      "  aggregatewordhist: An Aggregate based map/reduce program that computes the histogram of the words in the input files.\r\n",
      "  multifilewc: A job that counts words from several files.\r\n",
      "  wordcount: A map/reduce program that counts the words in the input files.\r\n",
      "  wordmean: A map/reduce program that counts the average length of the words in the input files.\r\n",
      "  wordmedian: A map/reduce program that counts the median length of the words in the input files.\r\n",
      "  wordstandarddeviation: A map/reduce program that counts the standard deviation of the length of the words in the input files.\r\n"
     ]
    }
   ],
   "source": [
    "# Hadoop available examples\n",
    "! hadoop jar $HADOOP_EXAMPLES | grep word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: wordcount <in> [<in>...] <out>\r\n"
     ]
    }
   ],
   "source": [
    "# Check wordcount\n",
    "! hadoop jar $HADOOP_EXAMPLES wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Note for my self: run this and next three cells 'live'\n",
    "\n",
    "########################\n",
    "# Preprocess with HDFS\n",
    "\n",
    "# Create input directory\n",
    "hdfs dfs -mkdir myinput\n",
    "# Save one file inside\n",
    "file=\"/data/lectures/data/books/twolines.txt\"\n",
    "hdfs dfs -put $file myinput/file01\n",
    "# Remove output or Hadoop will give error if existing\n",
    "hdfs dfs -rm -r -f myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/03/15 16:20:05 INFO client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8032\n",
      "16/03/15 16:20:06 INFO input.FileInputFormat: Total input paths to process : 1\n",
      "16/03/15 16:20:06 INFO mapreduce.JobSubmitter: number of splits:1\n",
      "16/03/15 16:20:06 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_1458056148609_0001\n",
      "16/03/15 16:20:07 INFO impl.YarnClientImpl: Submitted application application_1458056148609_0001\n",
      "16/03/15 16:20:07 INFO mapreduce.Job: The url to track the job: http://mapreduce:8088/proxy/application_1458056148609_0001/\n",
      "16/03/15 16:20:07 INFO mapreduce.Job: Running job: job_1458056148609_0001\n",
      "16/03/15 16:20:15 INFO mapreduce.Job: Job job_1458056148609_0001 running in uber mode : false\n",
      "16/03/15 16:20:15 INFO mapreduce.Job:  map 0% reduce 0%\n",
      "16/03/15 16:20:20 INFO mapreduce.Job:  map 100% reduce 0%\n",
      "16/03/15 16:20:27 INFO mapreduce.Job:  map 100% reduce 100%\n",
      "16/03/15 16:20:28 INFO mapreduce.Job: Job job_1458056148609_0001 completed successfully\n",
      "16/03/15 16:20:28 INFO mapreduce.Job: Counters: 49\n",
      "\tFile System Counters\n",
      "\t\tFILE: Number of bytes read=67\n",
      "\t\tFILE: Number of bytes written=212869\n",
      "\t\tFILE: Number of read operations=0\n",
      "\t\tFILE: Number of large read operations=0\n",
      "\t\tFILE: Number of write operations=0\n",
      "\t\tHDFS: Number of bytes read=162\n",
      "\t\tHDFS: Number of bytes written=41\n",
      "\t\tHDFS: Number of read operations=6\n",
      "\t\tHDFS: Number of large read operations=0\n",
      "\t\tHDFS: Number of write operations=2\n",
      "\tJob Counters \n",
      "\t\tLaunched map tasks=1\n",
      "\t\tLaunched reduce tasks=1\n",
      "\t\tData-local map tasks=1\n",
      "\t\tTotal time spent by all maps in occupied slots (ms)=3250\n",
      "\t\tTotal time spent by all reduces in occupied slots (ms)=4380\n",
      "\t\tTotal time spent by all map tasks (ms)=3250\n",
      "\t\tTotal time spent by all reduce tasks (ms)=4380\n",
      "\t\tTotal vcore-seconds taken by all map tasks=3250\n",
      "\t\tTotal vcore-seconds taken by all reduce tasks=4380\n",
      "\t\tTotal megabyte-seconds taken by all map tasks=3328000\n",
      "\t\tTotal megabyte-seconds taken by all reduce tasks=4485120\n",
      "\tMap-Reduce Framework\n",
      "\t\tMap input records=2\n",
      "\t\tMap output records=8\n",
      "\t\tMap output bytes=82\n",
      "\t\tMap output materialized bytes=67\n",
      "\t\tInput split bytes=113\n",
      "\t\tCombine input records=8\n",
      "\t\tCombine output records=5\n",
      "\t\tReduce input groups=5\n",
      "\t\tReduce shuffle bytes=67\n",
      "\t\tReduce input records=5\n",
      "\t\tReduce output records=5\n",
      "\t\tSpilled Records=10\n",
      "\t\tShuffled Maps =1\n",
      "\t\tFailed Shuffles=0\n",
      "\t\tMerged Map outputs=1\n",
      "\t\tGC time elapsed (ms)=120\n",
      "\t\tCPU time spent (ms)=950\n",
      "\t\tPhysical memory (bytes) snapshot=431710208\n",
      "\t\tVirtual memory (bytes) snapshot=1718702080\n",
      "\t\tTotal committed heap usage (bytes)=168497152\n",
      "\tShuffle Errors\n",
      "\t\tBAD_ID=0\n",
      "\t\tCONNECTION=0\n",
      "\t\tIO_ERROR=0\n",
      "\t\tWRONG_LENGTH=0\n",
      "\t\tWRONG_MAP=0\n",
      "\t\tWRONG_REDUCE=0\n",
      "\tFile Input Format Counters \n",
      "\t\tBytes Read=49\n",
      "\tFile Output Format Counters \n",
      "\t\tBytes Written=41\n"
     ]
    }
   ],
   "source": [
    "# Test wordcount with real hadoop on our system\n",
    "! hadoop jar $HADOOP_EXAMPLES wordcount myinput myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World Bye World\r\n",
      "Hello Hadoop Goodbye Hadoop"
     ]
    }
   ],
   "source": [
    "# This was our input\n",
    "! cat /data/lectures/data/books/twolines.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bye\t1\r\n",
      "Goodbye\t1\r\n",
      "Hadoop\t2\r\n",
      "Hello\t2\r\n",
      "World\t2\r\n"
     ]
    }
   ],
   "source": [
    "# This is our output\n",
    "! hadoop fs -cat myoutput/part*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recap\n",
    "<img src='https://pbs.twimg.com/media/B2RlCy-IIAEFCLC.jpg' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Write your first Java class to count letters inside a text file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*...just kidding!*\n",
    "\n",
    "> You may try to use hadoop commands within the notebook instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop like `pipes` in Unix Bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Prepare a data sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: myfile=/tmp/ngs.sam\n"
     ]
    }
   ],
   "source": [
    "# Variables for python and bash\n",
    "myfile = '/tmp/ngs.sam'\n",
    "%env myfile $myfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloaded\n",
      "decompressed\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Download compressed NGS data from a link\n",
    "wget -q \"http://bit.ly/ngs_sample_data\" -O $myfile.bz2 && echo \"downloaded\"\n",
    "# Decompress the file\n",
    "bunzip2 $myfile.bz2 && echo \"decompressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/ngs.sam\r\n"
     ]
    }
   ],
   "source": [
    "# Check if the file is there\n",
    "! ls $myfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 chr1:142803456\n",
      "      3 chr1:142803458\n",
      "      1 chr1:142803465\n",
      "      1 chr1:142803470\n",
      "      2 chr1:142803471\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Bash piping our own MapReduce with Unix commands\n",
    "head -2000 $myfile | tail -n 10 | awk '{ print $3\":\"$4 }' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Understanding better\n",
    "\n",
    "Splitting the command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. `head -2000 data/ngs/input.sam | tail -n 10`\n",
    "\n",
    "1. `awk '{ print $3\":\"$4 }’`\n",
    "\n",
    "1. `sort`\n",
    "\n",
    "1. `uniq -c`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**INPUT STREAM**\n",
    "`head -2000 data/ngs/input.sam | tail -n 10`\n",
    "\n",
    "**MAPPER**\n",
    "`awk '{ print $3\":\"$4 }'`\n",
    "\n",
    "**SHUFFLE**\n",
    "`sort`\n",
    "\n",
    "**REDUCER**\n",
    "`uniq -c`\n",
    "\n",
    "**OUTPUT STREAM**\n",
    "`<STDOUT>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's see step by step what it's happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HSCAN:421:C47DAACXX:3:1206:5660:99605\t99\tchr1\t142803456\t10\t75M\t=\t142803517\t136\tCTGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATA\t@@CDDDD?DBFHFHIHIJJJJGHEIFHIIIHGDFEGEIAHAHGIIGIIIC?CBFCGHFCEG?@DGIIIGHIGGHC\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746045,75M,0;chr1,+143355186,75M,0;chr1,-143233123,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:18\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:3:1207:14092:152623\t99\tchr1\t142803456\t0\t75M\t=\t142803560\t180\tCTGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATA\tCCCDFFFFHHHHGJJIJJJJJIJJJJJJJHIJJJJJIJJIJJJJJJJJIIIFHHEHJJIGHHIIJJJIIIJIIJG\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746045,75M,0;chr1,+143355186,75M,0;chr1,-143233123,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:0\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:3:1301:4054:177529\t99\tchr1\t142803456\t12\t75M\t=\t142803494\t113\tCTGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATA\tCCCFFFFFHHHHHJJHHJJIIGJJJJJJJIIGGIJJJJJJJJHIJJIIHIFFHIIJJJJJIGIJJHJEHHIGIIJ\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746045,75M,0;chr1,+143355186,75M,0;chr1,-143233123,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:20\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:2:1302:3204:111307\t99\tchr1\t142803458\t12\t75M\t=\t142803484\t101\tGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGA\tBCCFFFFFHHHHGCGIJIHHIHHIJJJJJJJIJIJIJJJJJJJJIJEHHHC<DHIIJJJIGIJIIJJJJJCHGE4\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746047,75M,0;chr1,+143355188,75M,0;chr1,-143233121,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:20\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:4:1103:18240:14393\t99\tchr1\t142803458\t0\t75M\t=\t142803580\t197\tGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGA\tCBCFFFFFHHHHGIJIJJJJJIHJJJJJJJJJIJJJJJJJIIGGIGHIEGFHIJJIJJIIIJJJJIIIIIIIJJ@\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746047,75M,0;chr1,+143355188,75M,0;chr1,-143233121,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:0\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:4:1107:18819:78768\t99\tchr1\t142803458\t12\t75M\t=\t142803495\t112\tGTGCATTCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGA\tB?BFDFFDHFFHHFGGIGJIIGIJHIIHGIIIGJIIJIJJJIIIJIJFEHGFHJEIJIGIIJIIJJJJIIJGGI:\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746047,75M,0;chr1,+143355188,75M,0;chr1,-143233121,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:20\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:3:1107:14197:140375\t99\tchr1\t142803465\t17\t75M\t=\t142803533\t143\tCTTATGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGATGTTGGA\t@@@BBD?DHHHABGE@FEHIFGHGHFHIIIIIICGHHIEIIHHIIH9FBGDFHGIIIIIIIIIIGHGEHIICGCF\tX0:i:3\tX1:i:1\tXA:Z:chr21,+9746054,75M,0;chr1,+143355195,75M,0;chr1,-143233114,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:0\tXM:i:0\tXO:i:0\tMQ:i:18\tXT:A:R\r\n",
      "HSCAN:421:C47DAACXX:4:1101:8419:153036\t99\tchr1\t142803470\t20\t75M\t=\t142803563\t168\tGATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGATGTTGGAATTCC\tB@BFFFFFHHHHHJIGGJIJJJJIJJJJIJIJJJIGJJIIJJJIIJIIJJHIGGGJIJJCHEHIGDGIGIIIEHG\tX0:i:1\tX1:i:2\tXA:Z:chr21,+9746059,75M,1;chr1,+143355200,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:20\tXM:i:0\tXO:i:0\tMQ:i:12\tXT:A:U\r\n",
      "HSCAN:421:C47DAACXX:1:1207:3548:56254\t163\tchr1\t142803471\t38\t75M\t=\t142803533\t137\tATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGATGTTGGAATTCCT\tBCCFFFEFHHHHHJJJJIJIJHJJGJIJJJJJJIHIHIJIIJJJJJHHGIHHIIIIJHJHIGIIJJJJEGGIJGH\tX0:i:1\tX1:i:2\tXA:Z:chr21,+9746060,75M,1;chr1,+143355201,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:18\tNM:i:0\tSM:i:20\tXM:i:0\tXO:i:0\tMQ:i:38\tXT:A:U\r\n",
      "HSCAN:421:C47DAACXX:4:1305:1710:37950\t99\tchr1\t142803471\t20\t75M\t=\t142803553\t157\tATTTTAATATTCTGTACATTTATTATTGATTTAAAATGCATTTTACCTTTTTCTTTAATAGATGTTGGAATTCCT\tCCCFFFFFHHHHGJIIJJJJJJJJIJJIJIJJJGIGIIJJJJJIIJEFHIGHGIJJIBHGIEEGGIIGGIGIGG@\tX0:i:1\tX1:i:2\tXA:Z:chr21,+9746060,75M,1;chr1,+143355201,75M,1;\tMD:Z:75\tRG:Z:1\tXG:i:0\tAM:i:0\tNM:i:0\tSM:i:20\tXM:i:0\tXO:i:0\tMQ:i:12\tXT:A:U\r\n"
     ]
    }
   ],
   "source": [
    "# STREAMING THE FILE\n",
    "! head -2000 $myfile | tail -n 10\n",
    "# note: \n",
    "# taking the last 10 lines of the first 2000\n",
    "# to skip headers lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1:142803456\r\n",
      "chr1:142803456\r\n",
      "chr1:142803456\r\n",
      "chr1:142803458\r\n",
      "chr1:142803458\r\n",
      "chr1:142803458\r\n",
      "chr1:142803465\r\n",
      "chr1:142803470\r\n",
      "chr1:142803471\r\n",
      "chr1:142803471\r\n"
     ]
    }
   ],
   "source": [
    "# MAPPING\n",
    "! head -2000 $myfile | tail -n 10 | awk '{ print $3\":\"$4 }'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1:142803456\r\n",
      "chr1:142803456\r\n",
      "chr1:142803456\r\n",
      "chr1:142803458\r\n",
      "chr1:142803458\r\n",
      "chr1:142803458\r\n",
      "chr1:142803465\r\n",
      "chr1:142803470\r\n",
      "chr1:142803471\r\n",
      "chr1:142803471\r\n"
     ]
    }
   ],
   "source": [
    "# SHUFFLING\n",
    "! head -2000 $myfile | tail -n 10 | awk '{ print $3\":\"$4 }' | sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      3 chr1:142803456\r\n",
      "      3 chr1:142803458\r\n",
      "      1 chr1:142803465\r\n",
      "      1 chr1:142803470\r\n",
      "      2 chr1:142803471\r\n"
     ]
    }
   ],
   "source": [
    "# REDUCER\n",
    "! head -2000 $myfile | tail -n 10 | awk '{ print $3\":\"$4 }' | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "<br>\n",
    "\n",
    "<big>\n",
    "Play *a little bit* with bash pipes. \n",
    "</big>\n",
    "\n",
    "Try to understand how MapReduce process data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Considerations with bash pipes as simulation of MapReduce\n",
    "\n",
    "* Serial steps\n",
    "* No file distribution\n",
    "* Single node\n",
    "* Single mapper\n",
    "* Single reducer\n",
    "* Can we add a Combiner?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Do you know how to substitute the awk/mapper with a python script?\n",
    "\n",
    "If yes, create one to count the most recurring words inside the Divine Comedy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Create a python script to count the vowels inside the Divine Comedy.\n",
    "\n",
    "(with bash pipes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Hadoop streaming\n",
    "### Concepts and mechanisms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hadoop streaming is a utility \n",
    "\n",
    "* It comes bundled with the Hadoop distribution\n",
    "* It allows creating and running Map/Reduce jobs \n",
    "    - with any executable or script as the mapper and/or the reducer\n",
    "\n",
    "Protocol steps\n",
    "\n",
    "* Create a Map/Reduce job\n",
    "* Submit the job to an appropriate cluster\n",
    "* Monitor the progress of the job until it completes\n",
    "* Links to Hadoop HDFS job directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Why?\n",
    "\n",
    "One of the most unappetizing aspects of Hadoop to users of traditional HPC is that it is written in Java. \n",
    "\n",
    "* Java is not originally designed to be a high-performance language\n",
    "* Learning Java is very difficult for domain scientists\n",
    "\n",
    "This is why Hadoop allows you to write map/reduce code in any language you want using the Hadoop Streaming interface\n",
    "\n",
    "* It means turning an existing Python or Perl script into a Hadoop job\n",
    "* Does not require learning any Java at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MapReduce streaming with binaries/executables\n",
    "\n",
    "* Executables are specified for mappers and reducers!\n",
    "    - each mapper task run as a separate process \n",
    "* Inputs converted into lines and feed to the `STDIN` of the process\n",
    "* The mapper collects `STDOUT` of the process \n",
    "    - each line is a key/value pair **separated by TAB**\n",
    "    - e.g. ”this is the key\\tvalue is the rest\\n”\n",
    "\n",
    "warning: If there is no tab character in the line, then entire line is considered as key and the value is null (!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<big> \n",
    "Let's go live\n",
    "</big> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A streaming command line example:\n",
    "``` bash\n",
    "$ hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "    -input myInputDirs \\\n",
    "    -output myOutputDir \\\n",
    "    -mapper org.apache.hadoop.mapred.lib.IdentityMapper \\\n",
    "    -reducer /bin/wc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "A streaming command line example **for python**:\n",
    "``` bash\n",
    "$ hadoop jar $HADOOP_HOME/hadoop-streaming.jar \\\n",
    "    -files mapper.py,reducer.py\n",
    "    -input input_dir/ \\\n",
    "    -output output_dir/ \\\n",
    "    -mapper mapper.py \\\n",
    "    -reducer reducer.py \\\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Before submitting the Hadoop Streaming job:\n",
    "\n",
    "* Make sure your scripts have no errors\n",
    "* Do mapper and reducer scripts actually work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "This is just a matter of running them through pipes on a **little bit** of sample data,\n",
    "\n",
    "like `cat` or `head` linux bash commands, with pipes, as seen before.\n",
    "\n",
    "```\n",
    "# Simulating hadoop streaming with bash pipes\n",
    "$ cat $file | python mapper.py | sort | python reducer.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "First approach: split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "import sys\n",
    "\n",
    "for line in sys.stdin:\n",
    "    line = line.strip()\n",
    "    pieces = line.split('\\t')\n",
    "    print(pieces) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@HD', 'VN:1.4', 'GO:none', 'SO:coordinate']\n",
      "['@SQ', 'SN:chrM', 'LN:16571']\n",
      "['@SQ', 'SN:chr1', 'LN:249250621']\n",
      "['@SQ', 'SN:chr2', 'LN:243199373']\n",
      "['@SQ', 'SN:chr3', 'LN:198022430']\n",
      "['@SQ', 'SN:chr4', 'LN:191154276']\n",
      "['@SQ', 'SN:chr5', 'LN:180915260']\n",
      "['@SQ', 'SN:chr6', 'LN:171115067']\n",
      "['@SQ', 'SN:chr7', 'LN:159138663']\n",
      "['@SQ', 'SN:chr8', 'LN:146364022']\n",
      "['@SQ', 'SN:chr9', 'LN:141213431']\n",
      "['@SQ', 'SN:chr10', 'LN:135534747']\n",
      "['@SQ', 'SN:chr11', 'LN:135006516']\n",
      "['@SQ', 'SN:chr12', 'LN:133851895']\n",
      "['@SQ', 'SN:chr13', 'LN:115169878']\n",
      "['@SQ', 'SN:chr14', 'LN:107349540']\n",
      "['@SQ', 'SN:chr15', 'LN:102531392']\n",
      "['@SQ', 'SN:chr16', 'LN:90354753']\n",
      "['@SQ', 'SN:chr17', 'LN:81195210']\n",
      "['@SQ', 'SN:chr18', 'LN:78077248']\n",
      "['@SQ', 'SN:chr19', 'LN:59128983']\n",
      "['@SQ', 'SN:chr20', 'LN:63025520']\n",
      "['@SQ', 'SN:chr21', 'LN:48129895']\n",
      "['@SQ', 'SN:chr22', 'LN:51304566']\n",
      "['@SQ', 'SN:chrX', 'LN:155270560']\n",
      "['@SQ', 'SN:chrY', 'LN:59373566']\n",
      "['@SQ', 'SN:chr1_gl000191_random', 'LN:106433']\n",
      "['@SQ', 'SN:chr1_gl000192_random', 'LN:547496']\n",
      "['@SQ', 'SN:chr4_ctg9_hap1', 'LN:590426']\n",
      "['@SQ', 'SN:chr4_gl000193_random', 'LN:189789']\n",
      "['@SQ', 'SN:chr4_gl000194_random', 'LN:191469']\n",
      "['@SQ', 'SN:chr6_apd_hap1', 'LN:4622290']\n",
      "['@SQ', 'SN:chr6_cox_hap2', 'LN:4795371']\n",
      "['@SQ', 'SN:chr6_dbb_hap3', 'LN:4610396']\n",
      "['@SQ', 'SN:chr6_mann_hap4', 'LN:4683263']\n",
      "['@SQ', 'SN:chr6_mcf_hap5', 'LN:4833398']\n",
      "['@SQ', 'SN:chr6_qbl_hap6', 'LN:4611984']\n",
      "['@SQ', 'SN:chr6_ssto_hap7', 'LN:4928567']\n",
      "['@SQ', 'SN:chr7_gl000195_random', 'LN:182896']\n",
      "['@SQ', 'SN:chr8_gl000196_random', 'LN:38914']\n",
      "['@SQ', 'SN:chr8_gl000197_random', 'LN:37175']\n",
      "['@SQ', 'SN:chr9_gl000198_random', 'LN:90085']\n",
      "['@SQ', 'SN:chr9_gl000199_random', 'LN:169874']\n",
      "['@SQ', 'SN:chr9_gl000200_random', 'LN:187035']\n",
      "['@SQ', 'SN:chr9_gl000201_random', 'LN:36148']\n",
      "['@SQ', 'SN:chr11_gl000202_random', 'LN:40103']\n",
      "['@SQ', 'SN:chr17_ctg5_hap1', 'LN:1680828']\n",
      "['@SQ', 'SN:chr17_gl000203_random', 'LN:37498']\n",
      "['@SQ', 'SN:chr17_gl000204_random', 'LN:81310']\n",
      "['@SQ', 'SN:chr17_gl000205_random', 'LN:174588']\n",
      "['@SQ', 'SN:chr17_gl000206_random', 'LN:41001']\n",
      "['@SQ', 'SN:chr18_gl000207_random', 'LN:4262']\n",
      "['@SQ', 'SN:chr19_gl000208_random', 'LN:92689']\n",
      "['@SQ', 'SN:chr19_gl000209_random', 'LN:159169']\n",
      "['@SQ', 'SN:chr21_gl000210_random', 'LN:27682']\n",
      "['@SQ', 'SN:chrUn_gl000211', 'LN:166566']\n",
      "['@SQ', 'SN:chrUn_gl000212', 'LN:186858']\n",
      "['@SQ', 'SN:chrUn_gl000213', 'LN:164239']\n",
      "['@SQ', 'SN:chrUn_gl000214', 'LN:137718']\n",
      "['@SQ', 'SN:chrUn_gl000215', 'LN:172545']\n",
      "['@SQ', 'SN:chrUn_gl000216', 'LN:172294']\n",
      "['@SQ', 'SN:chrUn_gl000217', 'LN:172149']\n",
      "['@SQ', 'SN:chrUn_gl000218', 'LN:161147']\n",
      "['@SQ', 'SN:chrUn_gl000219', 'LN:179198']\n",
      "['@SQ', 'SN:chrUn_gl000220', 'LN:161802']\n",
      "['@SQ', 'SN:chrUn_gl000221', 'LN:155397']\n",
      "['@SQ', 'SN:chrUn_gl000222', 'LN:186861']\n",
      "['@SQ', 'SN:chrUn_gl000223', 'LN:180455']\n",
      "['@SQ', 'SN:chrUn_gl000224', 'LN:179693']\n",
      "['@SQ', 'SN:chrUn_gl000225', 'LN:211173']\n",
      "['@SQ', 'SN:chrUn_gl000226', 'LN:15008']\n",
      "['@SQ', 'SN:chrUn_gl000227', 'LN:128374']\n",
      "['@SQ', 'SN:chrUn_gl000228', 'LN:129120']\n",
      "['@SQ', 'SN:chrUn_gl000229', 'LN:19913']\n",
      "['@SQ', 'SN:chrUn_gl000230', 'LN:43691']\n",
      "['@SQ', 'SN:chrUn_gl000231', 'LN:27386']\n",
      "['@SQ', 'SN:chrUn_gl000232', 'LN:40652']\n",
      "['@SQ', 'SN:chrUn_gl000233', 'LN:45941']\n",
      "['@SQ', 'SN:chrUn_gl000234', 'LN:40531']\n",
      "['@SQ', 'SN:chrUn_gl000235', 'LN:34474']\n",
      "['@SQ', 'SN:chrUn_gl000236', 'LN:41934']\n",
      "['@SQ', 'SN:chrUn_gl000237', 'LN:45867']\n",
      "['@SQ', 'SN:chrUn_gl000238', 'LN:39939']\n",
      "['@SQ', 'SN:chrUn_gl000239', 'LN:33824']\n",
      "['@SQ', 'SN:chrUn_gl000240', 'LN:41933']\n",
      "['@SQ', 'SN:chrUn_gl000241', 'LN:42152']\n",
      "['@SQ', 'SN:chrUn_gl000242', 'LN:43523']\n",
      "['@SQ', 'SN:chrUn_gl000243', 'LN:43341']\n",
      "['@SQ', 'SN:chrUn_gl000244', 'LN:39929']\n",
      "['@SQ', 'SN:chrUn_gl000245', 'LN:36651']\n",
      "['@SQ', 'SN:chrUn_gl000246', 'LN:38154']\n",
      "['@SQ', 'SN:chrUn_gl000247', 'LN:36422']\n",
      "['@SQ', 'SN:chrUn_gl000248', 'LN:39786']\n",
      "['@SQ', 'SN:chrUn_gl000249', 'LN:38502']\n",
      "['@RG', 'ID:1', 'PL:illumina', 'PU:unk_barcode', 'LB:flowcell', 'SM:file1']\n",
      "['@PG', 'ID:bwa', 'PN:bwa', 'VN:0.6.2-r126']\n",
      "['@PG', 'ID:GATK IndelRealigner', 'VN:2.5-2-gf57256b', 'CL:knownAlleles=[(RodBinding name=knownAlleles source=/gpfs/scratch/project/EPIGEN/db/35/1000G_phase1.indels.hg19.vcf), (RodBinding name=knownAlleles2 source=/gpfs/scratch/project/EPIGEN/db/35/dbsnp_135.hg19.vcf)] targetIntervals=/gpfs/scratch/project/EPIGEN/db/35/hg19.intervals LODThresholdForCleaning=0.4 consensusDeterminationModel=KNOWNS_ONLY entropyThreshold=0.15 maxReadsInMemory=300000 maxIsizeForMovement=3000 maxPositionalMoveAllowed=200 maxConsensuses=30 maxReadsForConsensuses=120 maxReadsForRealignment=20000 noOriginalAlignmentTags=false nWayOut=null generate_nWayOut_md5s=false check_early=false noPGTag=false keepPGTags=false indelsFileForDebugging=null statisticsFileForDebugging=null SNPsFileForDebugging=null']\n",
      "['HSCAN:421:C47DAACXX:4:1202:4115:156718', '121', 'chrM', '14', '37', '75M', '=', '14', '0', 'TCACCCTATTAACCACTCACGGGAGCTCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCAT', '<?9?@DDDDDDCDCCDDDDDDECCDFCHHBFHEGIIIEGJJJJIGGJIJJJIJJJJJJJIIJHHHHHFFFFFCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:0', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1202:4115:156718', '181', 'chrM', '14', '0', '*', '=', '14', '0', 'GATAGACCTGTGATCCATCGTGATGTCTTATTTAAGGGGAACGTGTGGGCTATTTAGGCTTTATGACCCTGAAGT', 'DFFEC=HFIGHJIGGJIJJJIIGHHJIIIHCGJJJJJJJJGIJJJIIHF<HCIIIIIJHJIJHHHHHFFFFFCC@', 'RG:Z:1']\n",
      "['HSCAN:421:C47DAACXX:1:1307:12098:142207', '163', 'chrM', '19', '60', '75M', '=', '40', '96', 'CTATTAACCACTCACGGGAGCTCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGA', 'CCCFFFFFHHHHHJJJJJIJJJJJIJJJJIIIJJIJFHIJJJJIHJJJIJIJD:<:@CEDDDDBDBDDDEDDDDB', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1103:14128:52270', '99', 'chrM', '28', '60', '75M', '=', '83', '130', 'ACTCACGGGAGCTCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGAGACGCTGGA', 'BCCFFFFFHHHGHIIJJJJJJIIJJJJGGIIJJJIHIJJHJIEBBDDBDECBDBDDBBCCDDDCBBDDDBDDDDD', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1307:12098:142207', '83', 'chrM', '40', '60', '75M', '=', '19', '-96', 'TCTCCATGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGAGACGCTGGAGCCGGAGCACCC', 'ADC?CADDCA?CDDDDCDDDBDDB?ADHHEJIIGAGGHIGHHGHHHGGHBGIIHIIJIIIJJGHGHHFFFDD@CC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1204:12693:2591', '16', 'chrM', '46', '37', '75M', '*', '0', '0', 'TGCATTTGGTATTTTCGTCTGGGGGGTGTGCACGCGATAGCATTGCGAGACGCTGGAGCCGGAGCACCCTATGTC', 'CCCCBDDDDDDB7DBDDDD?DCEFHHHIIGHAJIHIIHGJJJJJIGIJJJIIGGJJJJJJJJHHHFHFFFFFCCB', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'NM:i:0', 'XM:i:0', 'XO:i:0', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1107:17435:114511', '99', 'chrM', '82', '60', '75M', '=', '108', '101', 'ATAGCATTGCGAGACGCTGGAGCCGGAGCACCCTATGTCGCAGTATCTGTCTTTGATTCCTGCCTCATCCTATTA', 'CCCFFFFFHHGHHHIHJJJJGIIJJJGIIGIIJJIJJIJJJHIAGGHHHHHHHFFFFFFFEEEEEEDCDDDCCDE', 'X0:i:1', 'X1:i:0', 'MD:Z:68T6', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1103:14128:52270', '147', 'chrM', '83', '60', '75M', '=', '28', '-130', 'TAGCATTGCGAGACGCTGGAGCCGGAGCACCCTATGTCGCAGTATCTGTCTTTGATTCCTGCCTCATCCTATTAT', 'CDCC@DDBEEDDFFFHHHHJJJJHJIHFBJJJJJIJJJJJIJJJIIGGIHIJJJJIIJJJJJHHHHHFFFFFC@@', 'X0:i:1', 'X1:i:0', 'MD:Z:67T7', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1107:17435:114511', '147', 'chrM', '108', '60', '75M', '=', '82', '-101', 'AGCACCCTATGTCGCAGTATCTGTCTTTGATTCCTGCCTCATCCTATTATTTATCGCACCTACGTTCAATATTAC', 'A?=.DD@CFFHBGHCGFF=CBFBC<HGGFCF@IFFDIGGGIGJIIJJIJJJJIIJHFEJHHGHHGHHFFFFFBB@', 'X0:i:1', 'X1:i:0', 'MD:Z:42T32', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:7495:73321', '163', 'chrM', '149', '60', '75M', '=', '257', '184', 'TCCTATTATTTATCGCACCTACGTTCAATATTACAGGCGAACATACTTACTAAAGTGTGTTAATTAATTAATGCT', '@@@FFFFFHHHHHJIJGGJIEIIJJJIJJIIJIIJJJIJIIJJJJJJJGIFHHICCDCGCHIJFHHHHHHFFFFF', 'X0:i:1', 'X1:i:0', 'MD:Z:1T44C28', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:2', 'SM:i:37', 'XM:i:2', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1105:11738:114484', '99', 'chrM', '149', '60', '75M', '=', '168', '94', 'TCCTATTATTTATCGCACCTACGTTCAATATTACAGGCGAACATACTTACTAAAGTGTGTTAATTAATTAATGCT', 'CCCFFFFFHHHGHJJJJJIIGHHFHHIIIIIICHHIIIIIIFIIHIJJJIFHGHJFEGCHAGGEEEEECHFFFFC', 'X0:i:1', 'X1:i:0', 'MD:Z:1T44C28', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:2', 'SM:i:37', 'XM:i:2', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1105:11738:114484', '147', 'chrM', '168', '60', '75M', '=', '149', '-94', 'TACGTTCAATATTACAGGCGAACATACTTACTAAAGTGTGTTAATTAATTAATGCTTGTAGGACATAATAATAAC', 'AHGGFGHIJJIIIJJJJJIJJIIFBBJJIIJJIJJJJJJJIJJIGGJJIJJJJIJJJJIJJJHFHGHFFFFFC@C', 'X0:i:1', 'X1:i:0', 'MD:Z:27C47', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1202:10755:139463', '163', 'chrM', '228', '60', '75M', '=', '267', '115', 'GGACATAATAATAACAATTGAATGTCTGCACAGCCGCTTTCCACACAGACATCATAACAAAAAATTTCCACCAAA', 'CCCFFFFFHHHHHJJHGIEHIJIEDHIIJJJIJJIJJGGEIJJJJJJJGIGHIGGGIIIJJJDHHHHHFFFFFBC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1305:17890:179573', '99', 'chrM', '233', '60', '75M', '=', '272', '115', 'TAATAATAACAATTGAATGTCTGCACAGCCGCTTTCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCC', '@@@FFFFFDDHFDIBFFGI?FGF>?@HGIIIIIDEHIIIIIG>@DHIIGB?B@FFAFEHAGACH;A?A??B?AA@', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1108:18523:188393', '163', 'chrM', '250', '60', '53M1D22M', '=', '252', '78', 'TGTCTGCACAGCCGCTTTCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGG', 'CCBFFFFFHHHHHJJIIGHJJJJJJJGIJJJJJJJJIJJCHHIGGIJJJJFIIJJIHGDB?DBDBBD7@>>BC::', 'X0:i:1', 'X1:i:0', 'MD:Z:53^C22', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1108:18523:188393', '83', 'chrM', '252', '60', '51M1D24M', '=', '250', '-78', 'TCTGCACAGCCGCTTTCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCC', 'CCDDDDDDDBDDDDDDDDCCCDDDDDEDDECCBDDDDDDDDCBB@?DDB<5DDDDDB<5DJIHHHHHFFFFF@@@', 'X0:i:1', 'X1:i:0', 'MD:Z:51^C24', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:7495:73321', '83', 'chrM', '257', '60', '46M1D29M', '=', '149', '-184', 'ACAGCCGCTTTCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCCACAGC', '#B@;DDCBDDCDBACCAAC@>>A@@>?BBDDDDCCDC??82B@?0&DDDB<56&DJJJIGBGHHGHFDDFFFCC@', 'X0:i:1', 'X1:i:0', 'MD:Z:46^C29', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:16770:138078', '163', 'chrM', '264', '60', '39M1D36M', '=', '305', '116', 'CTTTCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCCACAGAACTTAAA', '@BCFFFFFHHFHDHJJJJJJJJJJJJJIJJJJJJJJJIJIJJJIJG:ABDDCD######################', 'X0:i:1', 'X1:i:0', 'MD:Z:39^C28C7', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:2', 'SM:i:37', 'XM:i:1', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1202:10755:139463', '83', 'chrM', '267', '60', '36M1D39M', '=', '228', '-115', 'TCCACACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCCACAGCACTTAAACAC', 'A@A>ACCC@:@>A@CCCA9BCC>93CA??2(?<8)&DBDDBB:-DJIJJJIJJJIGIIIIHGBHHHGFFFFFCB@', 'X0:i:1', 'X1:i:0', 'MD:Z:36^C39', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1305:17890:179573', '147', 'chrM', '272', '60', '31M1D44M', '=', '233', '-115', 'ACAGACATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCCACAGCACTTAAACACATCTC', 'CDDC@C@ACDCA?;DCCCDDCA<<+2B??5&DDB@BDBDDFGHF@FIGGJGHHBIIFJIGFIHHHHHDDFFFB@@', 'X0:i:1', 'X1:i:0', 'MD:Z:31^C44', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1102:12363:112587', '163', 'chrM', '277', '60', '26M1D49M', '=', '339', '137', 'CATCATAACAAAAAATTTCCACCAAACCCCCCCTCCCCCCGCTTCTGGCCACAGCACTTAAACACATCTCTGCCA', 'CCCFFFFFHHHHHJJJJJJJJJJIIJJJJJIJIIIJJJIFDDBDB;;@CBCDBDDCDDDDDDCCABCDDDDDDDD', 'X0:i:1', 'X1:i:0', 'MD:Z:26^C49', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:0', 'XO:i:1', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:16770:138078', '83', 'chrM', '305', '60', '75M', '=', '264', '-116', 'CCCCCCTCCCCCCGCTTCTGGCCACAGAACTTAAACACATCTCTGCCAAACCCCAAAAACAAAGAACCCTAACAC', '@DDDB;5DDDFFHHJJIJJJJIIJJIIGCIJJIGHGDJIHFDIJJIGIHFJJIGJJIIHJJJHHHFHFFFFD@@B', 'X0:i:1', 'X1:i:0', 'MD:Z:27C47', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1102:12363:112587', '83', 'chrM', '339', '60', '75M', '=', '277', '-137', 'ACACATCTCTGCCAAACCCCAAAAACAAAGAACCCTAACACCAGCCTAACCAGATTTCAAATTTTATCTTTTGGC', 'DACECCFEFHGGEIHGIJIIIJJJJJJGHFHBIIIHGFFEJJJJJJIHFJJJJJJJJJJIJJHHHHHFFFFFCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:71A3', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1101:10550:107730', '163', 'chrM', '371', '60', '75M', '=', '409', '113', 'CCCTAACACCAGCCTAACCAGATTTCAAATTTTATCTTTTGGCGGTATGCACTTTTAACAGTCACCCCCCAACTA', 'CCCFFFFFHHHHHJJJJJJJJGHJIIJIJJJJJJJJJJJJJJIJJGGIJGFHHIJJJJJHHHHFGFFFDDBDDDD', 'X0:i:1', 'X1:i:0', 'MD:Z:39A35', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1101:10550:107730', '83', 'chrM', '409', '60', '75M', '=', '371', '-113', 'TTGGCGGTATGCACTTTTAACAGTCACCCCCCAACTAACACATTATTTTCCCCTCCCACTCCCATACTACTAATC', '@>DB>?4DDDDDDDDDEDCDDDCA57DHJJIIHGIHGFEIJJJJIIJIHJJIHFIHF?IHJJHHGHHEDFFFCBB', 'X0:i:1', 'X1:i:0', 'MD:Z:1A73', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1308:17750:164633', '163', 'chrM', '485', '37', '75M', '=', '628', '218', 'CATCAATACAACCCCCGCCCATCCTACCCAGCACACACACACCGCTGCTAACCCCATACCCCGAACCAACCAAAC', 'CCCFFFFFHHHHHEHEEAFH:?FGIGGIBFDDCGHGIJGIGGABHBEEFD@DDDDCCDDDDD?B8=@AA?@?BDD', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:0', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:29', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1308:2299:130906', '99', 'chrM', '485', '60', '75M', '=', '530', '120', 'CATCAATACAACCCCCGCCCATCCTACCCAGCACACACACACCGCTGCTAACCCCATACCCCGAACCAACCAAAC', 'CBCFFFFFHHGHHJJJGJJJJIGJJJJJIJJIJJJJJJJJJJJJIHGFFFFFFDDCDCCDDDDDBDDD<@DDDB?', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1308:2299:130906', '147', 'chrM', '530', '60', '75M', '=', '485', '-120', 'TGCTAACCCCATACCCCGAACCAACCAAACCCCAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGC', 'CDDDDDDDCDD@7DDBDDDBDDDBBDDBDDDDDDDDC<<7DJJJJHHIJJJJJIJJJJJIHFDGHDHFFFFFCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1306:15086:33707', '99', 'chrM', '531', '60', '75M', '=', '567', '111', 'GCTAACCCCATACCCCGAACCAACCAAACCCCAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCA', 'CCCFFFFFHHFFFIIJIGIGJIGHIGIIIJJIIJIIJJJGHHIHFFFCEA>AEDDDFEDDDDDDDDDDCCCCDCD', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1202:4049:199082', '99', 'chrM', '536', '60', '75M', '=', '562', '101', 'CCCCATACCCCGAACCAACCAAACCCCAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCAATACA', 'CCCFFDDBHHHDAHDHEHEHGHIFFIJJIJJJIEFHHIJJEE=BCECEFFECECEEEDDDDDCCCCDCDDDDDD>', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1208:4238:56499', '99', 'chrM', '537', '60', '75M', '=', '540', '78', 'CCCATACCCCGAACCAACCAAACCCCAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCAATACAC', 'CCCFFFFFHHHHHJJJJJJJJJIJJJJIJFHJJJJJJJIIHHHFFFFFFFBEDEEEDCDDDDCDDDCCCCCCDDA', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1208:4238:56499', '147', 'chrM', '540', '60', '75M', '=', '537', '-78', 'ATACCCCGAACCAACCAAACCCCAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCAATACACTGA', ':;5BDDDDDDDDDDDDDB<DDDDDCCC9:5DJIJGHGJJJJJJJJJIJJJIGCIHFJIHJJJHHHHHFDDDD?:=', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1202:4049:199082', '147', 'chrM', '562', '60', '75M', '=', '536', '-101', 'CAAAGACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCAATACACTGAAAATGTTTAGACGGGCTCACAT', 'DDCCA9;0DHIJIHFJJJJJIJJIJJJJJIHJJJJJFJJJIIJIIEGIHJJJJJJJJJJJJIHHHHHFFFFFCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1306:15086:33707', '147', 'chrM', '567', '60', '75M', '=', '531', '-111', 'ACACCCCCCACAGTTTATGTAGCTTACCTCCTCAAAGCAATACACTGAAAATGTTTAGACGGGCTCACATCACCC', '9>;DFHHHEFJJJJJJJJJJJIHGEBIJIIIJJIJIJJJJIGHIJJJJJJJJJJJJJJIJJJHHGHFFFFFDCBB', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1303:15744:164062', '163', 'chrM', '601', '60', '75M', '=', '677', '151', 'AAGCAATACACTGAAAATGTTTAGACGGGCTCACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTAT', 'CCCDDFFFHHHHHIJJIIJJJJJJJJJIJJJJJJJJJJJJJJJJJIJJJJJIJJJGIGIIIIJJHHHGHFFFFFF', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1201:17236:66922', '99', 'chrM', '603', '60', '75M', '=', '727', '199', 'GCAATACACTGAAAATGTTTAGACGGGCTCACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTA', 'CCCFFFFFHDHHHJIGJHHJJIJGEAHIIJHJIJIIGIIIIJGEHJIJ(BCHH@FEGHIJIJIIGEHHHFFF@CE', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1308:17750:164633', '83', 'chrM', '628', '29', '75M', '=', '485', '-218', 'GGCTCACATCACCCCATAAACAAATAGGTTTGGTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAA', '??=.)7.7654EFC=>CF??98F?9B8?FB:AFDAEE911<29FA:<4EA:3+FCC<AA::GC<?=D=BDDD@@@', 'X0:i:2', 'X1:i:0', 'XA:Z:chr2,+149639337,75M,0;', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:0', 'NM:i:0', 'SM:i:0', 'XM:i:0', 'XO:i:0', 'MQ:i:37', 'XT:A:R']\n",
      "['HSCAN:421:C47DAACXX:4:1202:7112:84176', '99', 'chrM', '660', '60', '75M', '=', '705', '120', 'GTCCTAGCCTTTCTATTAGCTCTTAGTAAGATTACACATGCAAGCATCCCCGTTCCAGTGAGTTCACCCTCTAAA', 'CCCFFFFFHHHHHJJIJCCGHHDHHGHIJJJJJJGIGEIIHIHIJIIJGGGHIHIGIGBHIBBFCHIIJJ9@=7=', 'X0:i:1', 'X1:i:1', 'XA:Z:chr2,-149639305,75M,1;', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:23', 'NM:i:0', 'SM:i:23', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1303:15744:164062', '83', 'chrM', '677', '60', '75M', '=', '601', '-151', 'AGCTCTTAGTAAGATTACACATGCAAGCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGG', '@EEFFFDFGGHHHE?GEJHJIIIIHJJJJIJJIJIJJJJJJIJJJJIGFJFJGIIJJIGGDIHFHHHFFFFFCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1205:10886:107193', '145', 'chrM', '677', '37', '75M', '=', '679', '-73', 'AGCTCTTAGTAAGATTACACATGCAAACATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGG', 'CEB@@@FGGHHHA;DD@IHHDC@==)=F:A@EGJGHGF9DCDFAEEFC2GGGDHEGHGBFEIHD1DGFDDBF@@=', 'X0:i:1', 'X1:i:0', 'MD:Z:26G48', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1205:10886:107193', '97', 'chrM', '679', '37', '75M', '=', '677', '73', 'CTCTTAGTAAGATTACACATGCAAACATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGCT', '@@CFFFDEHHBFHHIIEGHIGGIJJGIIIJJJJJIJGIIFHIJG>DFGHH?FHICEGIJJ;@@FBHGIHDHGED@', 'X0:i:1', 'X1:i:0', 'MD:Z:24G48G0A0', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:3', 'SM:i:37', 'XM:i:3', 'XO:i:0', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:18439:25062', '163', 'chrM', '681', '60', '75M', '=', '791', '185', 'CTTAGTAAGATTACACATGCAAGCATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGGACA', 'CCCFFFFFHHHHHJJJJJJJJGIFJJJJJJJIJJJJJHIIJIJIJHIJJJIIJJJJJJJJJJJJIJJIHHHFEEB', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1202:7112:84176', '147', 'chrM', '705', '60', '75M', '=', '660', '-120', 'ATCCCCGTTCCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGGACAAGCATCAAGCACGCAGCAATGCAG', '#BDFFHEHHJIGIIIIHGF@1GGJHIHGIFJIHJGJIGFDFJIIHGFCG9HGHF9GGIIIGHGHHHHFFFFF@@@', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:23', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1107:11994:91694', '163', 'chrM', '714', '60', '75M', '=', '803', '164', 'CCAGTGAGTTCACCCTCTAAATCACCACGATCAAAAGGGACAAGCATCAAGCACGCAGCAATGCAGCTCAAAACG', 'CCCFFFFFHHHHHJJJJJJJJJIJJJJJJJJJJJJJJJJIJJIJJJJJJJHIIIIIIGEHAHFFFFFFFDCCCBB', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:1:1201:17236:66922', '147', 'chrM', '727', '60', '75M', '=', '603', '-199', 'CCTCTAAATCACCACGATCAAAAGGGACAAGCATCAAGCACGCAGCAATGCAGCTCAAAACGCTTAGCCTAGCCA', '@;6.)@B?:?6:(7(==5;GA@7C=GFBGCIEIIGIIEGEHGGEGBIIIGCCEHAFIGHEJIHHHHHFFFDA@@@', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1305:11279:167218', '81', 'chrM', '751', '37', '75M', '=', '757', '-69', 'AGACAGGCATCAAGCACGCAGCAATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGA', \"########C@:55,'@;>CCCA;(;@?7@55(C=55BHA@8BCG@GB@B;D8)AHEC@;IHE??HFFABDD?@@@\", 'X0:i:1', 'X1:i:0', 'MD:Z:0G4A69', 'RG:Z:1', 'XG:i:0', 'AM:i:25', 'NM:i:2', 'SM:i:37', 'XM:i:2', 'XO:i:0', 'MQ:i:25', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1305:11279:167218', '161', 'chrM', '757', '25', '75M', '=', '751', '69', 'GCATCAAGCACGCAGCAATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGACTGTCT', \"@?<D?D;DFFDFDDF6EGIJ@HC<FEFFHGF@@DB@DFDHCEGHIAHE;@4;AEH8B'365>;A=AC>ACC>:A>\", 'X0:i:1', 'X1:i:0', 'MD:Z:69T1A0A1C0', 'RG:Z:1', 'XG:i:0', 'AM:i:25', 'NM:i:4', 'SM:i:25', 'XM:i:4', 'XO:i:0', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1208:10198:124715', '99', 'chrM', '774', '60', '75M', '=', '803', '104', 'ATGCAGCTCAAAACGCTTAGCCTAGCCACACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAA', '@BBDBDDFHHHHGIHHJJJJJIIIIIEGFFFH?FHIHIEIHHE=FGGCE)=AEHHHFFFDFECCCEECDA@@BB@', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:2:1203:18439:25062', '83', 'chrM', '791', '60', '75M', '=', '681', '-185', 'TAGCCTAGCCACACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAAGTTTAACTAAGCTATAC', 'DDDDDC?DCA=B=JIIIHFIJIHHFHIJJJJJJJIHHHBIJJJIIJIJJJIHGJIJJJJJIIHHHHHFFFFFCBC', 'X0:i:1', 'X1:i:0', 'MD:Z:75', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:0', 'SM:i:37', 'XM:i:0', 'XO:i:0', 'MQ:i:60', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1107:16496:141822', '145', 'chrM', '791', '37', '75M', '=', '792', '-74', 'GAGCCTAGCCACACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAAGTTTAACTAAGCTATAC', 'BDDDDDDDDDB?:EIHGHFIIHIGGDJIJIJJJIIJIHDJJJJIJJJJIIJJGJJJJJJJJJHHHHHFFFFFB@C', 'X0:i:1', 'X1:i:0', 'MD:Z:0T74', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:3:1107:16496:141822', '97', 'chrM', '792', '37', '75M', '=', '791', '74', 'AGCCTAGCCACACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAAGTTTAACTAAGCTATACC', 'CCCFFFFFHGHHHJJJJJJJJJGJJJJJIJJJJJJJJJGHIJIIJIJJIGIFHIBEHHEFFFFFFECEEECCDDC', 'X0:i:1', 'X1:i:0', 'MD:Z:74T0', 'RG:Z:1', 'XG:i:0', 'AM:i:37', 'NM:i:1', 'SM:i:37', 'XM:i:1', 'XO:i:0', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1208:18817:185709', '81', 'chrM', '797', '37', '5M1I69M', '=', '802', '-69', 'AGACAGCACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAAGTTTAACTAAGCTATACTAACC', 'CC@CC?=DHIIGGHEDDGGIGJIGGEHCIHDFF?IIIJJJJJIJJIGIJJHIEIGIGGIIJJHFHGHEDFDD=@@', 'X0:i:1', 'X1:i:0', 'MD:Z:2C71', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:2', 'SM:i:37', 'XM:i:1', 'XO:i:1', 'MQ:i:37', 'XT:A:U']\n",
      "['HSCAN:421:C47DAACXX:4:1208:18817:185709', '161', 'chrM', '802', '37', '67M1D8M', '=', '797', '69', 'CACCCCCACGGGAAACAGCAGTGATTAACCTTTAGCAATAAACGAAAGTTTAACTAAGCTATACTAACCCTGTCT', 'CCCFFFFFHHHGHJJIJGIJJJIGIJJJJIIJJJJJJEIJJIJGI=FHGIHHGGIIGIHBHFGHFFFFFDECCCC', 'X0:i:1', 'X1:i:0', 'MD:Z:67^C3A1G0G1', 'RG:Z:1', 'XG:i:1', 'AM:i:37', 'NM:i:4', 'SM:i:37', 'XM:i:3', 'XO:i:1', 'MQ:i:37', 'XT:A:U']\n"
     ]
    }
   ],
   "source": [
    "! head -n 150 $myfile | python mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Count symbols (everything that is not a letter of the alphabet) inside a text file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Back to the example:\n",
    "\n",
    "Skip header lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "TAB = \"\\t\"\n",
    "import sys\n",
    "\n",
    "# Cycle current streaming data\n",
    "for line in sys.stdin:\n",
    "\n",
    "    # Clean input\n",
    "    line = line.strip()\n",
    "    # Skip SAM/BAM headers\n",
    "    if line[0] == \"@\":\n",
    "        continue\n",
    "\n",
    "    # Use data\n",
    "    pieces = line.split(TAB)\n",
    "    mychr = pieces[2]\n",
    "    mystart = int(pieces[3])\n",
    "    myseq = pieces[9]\n",
    "    print(mychr,mystart.__str__())\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrM 14\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 100 $myfile | python mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Produce an output that can be sorted and then used by reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "TAB = \"\\t\"\n",
    "SEP = ':'\n",
    "import sys\n",
    "\n",
    "# Cycle current streaming data\n",
    "for line in sys.stdin:\n",
    "    # Clean input\n",
    "    line = line.strip()\n",
    "    # Skip SAM/BAM headers\n",
    "    if line[0] == \"@\":\n",
    "        continue\n",
    "    \n",
    "    # Use data\n",
    "    pieces = line.split(TAB)\n",
    "    mychr = pieces[2]\n",
    "    mystart = int(pieces[3])\n",
    "    myseq = pieces[9]\n",
    "\n",
    "    mystop = mystart + len(myseq)\n",
    "\n",
    "    # Each element with coverage\n",
    "    for i in range(mystart,mystop):\n",
    "        results = [mychr+SEP+i.__str__(), \"1\"]\n",
    "        print(TAB.join(results))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrM:14\t1\r\n",
      "chrM:15\t1\r\n",
      "chrM:16\t1\r\n",
      "chrM:17\t1\r\n",
      "chrM:18\t1\r\n",
      "chrM:19\t1\r\n",
      "chrM:20\t1\r\n",
      "chrM:21\t1\r\n",
      "chrM:22\t1\r\n",
      "chrM:23\t1\r\n",
      "chrM:24\t1\r\n",
      "chrM:25\t1\r\n",
      "chrM:26\t1\r\n",
      "chrM:27\t1\r\n",
      "chrM:28\t1\r\n",
      "chrM:29\t1\r\n",
      "chrM:30\t1\r\n",
      "chrM:31\t1\r\n",
      "chrM:32\t1\r\n",
      "chrM:33\t1\r\n",
      "chrM:34\t1\r\n",
      "chrM:35\t1\r\n",
      "chrM:36\t1\r\n",
      "chrM:37\t1\r\n",
      "chrM:38\t1\r\n",
      "chrM:39\t1\r\n",
      "chrM:40\t1\r\n",
      "chrM:41\t1\r\n",
      "chrM:42\t1\r\n",
      "chrM:43\t1\r\n",
      "chrM:44\t1\r\n",
      "chrM:45\t1\r\n",
      "chrM:46\t1\r\n",
      "chrM:47\t1\r\n",
      "chrM:48\t1\r\n",
      "chrM:49\t1\r\n",
      "chrM:50\t1\r\n",
      "chrM:51\t1\r\n",
      "chrM:52\t1\r\n",
      "chrM:53\t1\r\n",
      "chrM:54\t1\r\n",
      "chrM:55\t1\r\n",
      "chrM:56\t1\r\n",
      "chrM:57\t1\r\n",
      "chrM:58\t1\r\n",
      "chrM:59\t1\r\n",
      "chrM:60\t1\r\n",
      "chrM:61\t1\r\n",
      "chrM:62\t1\r\n",
      "chrM:63\t1\r\n",
      "chrM:64\t1\r\n",
      "chrM:65\t1\r\n",
      "chrM:66\t1\r\n",
      "chrM:67\t1\r\n",
      "chrM:68\t1\r\n",
      "chrM:69\t1\r\n",
      "chrM:70\t1\r\n",
      "chrM:71\t1\r\n",
      "chrM:72\t1\r\n",
      "chrM:73\t1\r\n",
      "chrM:74\t1\r\n",
      "chrM:75\t1\r\n",
      "chrM:76\t1\r\n",
      "chrM:77\t1\r\n",
      "chrM:78\t1\r\n",
      "chrM:79\t1\r\n",
      "chrM:80\t1\r\n",
      "chrM:81\t1\r\n",
      "chrM:82\t1\r\n",
      "chrM:83\t1\r\n",
      "chrM:84\t1\r\n",
      "chrM:85\t1\r\n",
      "chrM:86\t1\r\n",
      "chrM:87\t1\r\n",
      "chrM:88\t1\r\n",
      "chrM:14\t1\r\n",
      "chrM:15\t1\r\n",
      "chrM:16\t1\r\n",
      "chrM:17\t1\r\n",
      "chrM:18\t1\r\n",
      "chrM:19\t1\r\n",
      "chrM:20\t1\r\n",
      "chrM:21\t1\r\n",
      "chrM:22\t1\r\n",
      "chrM:23\t1\r\n",
      "chrM:24\t1\r\n",
      "chrM:25\t1\r\n",
      "chrM:26\t1\r\n",
      "chrM:27\t1\r\n",
      "chrM:28\t1\r\n",
      "chrM:29\t1\r\n",
      "chrM:30\t1\r\n",
      "chrM:31\t1\r\n",
      "chrM:32\t1\r\n",
      "chrM:33\t1\r\n",
      "chrM:34\t1\r\n",
      "chrM:35\t1\r\n",
      "chrM:36\t1\r\n",
      "chrM:37\t1\r\n",
      "chrM:38\t1\r\n",
      "chrM:39\t1\r\n",
      "chrM:40\t1\r\n",
      "chrM:41\t1\r\n",
      "chrM:42\t1\r\n",
      "chrM:43\t1\r\n",
      "chrM:44\t1\r\n",
      "chrM:45\t1\r\n",
      "chrM:46\t1\r\n",
      "chrM:47\t1\r\n",
      "chrM:48\t1\r\n",
      "chrM:49\t1\r\n",
      "chrM:50\t1\r\n",
      "chrM:51\t1\r\n",
      "chrM:52\t1\r\n",
      "chrM:53\t1\r\n",
      "chrM:54\t1\r\n",
      "chrM:55\t1\r\n",
      "chrM:56\t1\r\n",
      "chrM:57\t1\r\n",
      "chrM:58\t1\r\n",
      "chrM:59\t1\r\n",
      "chrM:60\t1\r\n",
      "chrM:61\t1\r\n",
      "chrM:62\t1\r\n",
      "chrM:63\t1\r\n",
      "chrM:64\t1\r\n",
      "chrM:65\t1\r\n",
      "chrM:66\t1\r\n",
      "chrM:67\t1\r\n",
      "chrM:68\t1\r\n",
      "chrM:69\t1\r\n",
      "chrM:70\t1\r\n",
      "chrM:71\t1\r\n",
      "chrM:72\t1\r\n",
      "chrM:73\t1\r\n",
      "chrM:74\t1\r\n",
      "chrM:75\t1\r\n",
      "chrM:76\t1\r\n",
      "chrM:77\t1\r\n",
      "chrM:78\t1\r\n",
      "chrM:79\t1\r\n",
      "chrM:80\t1\r\n",
      "chrM:81\t1\r\n",
      "chrM:82\t1\r\n",
      "chrM:83\t1\r\n",
      "chrM:84\t1\r\n",
      "chrM:85\t1\r\n",
      "chrM:86\t1\r\n",
      "chrM:87\t1\r\n",
      "chrM:88\t1\r\n",
      "chrM:19\t1\r\n",
      "chrM:20\t1\r\n",
      "chrM:21\t1\r\n",
      "chrM:22\t1\r\n",
      "chrM:23\t1\r\n",
      "chrM:24\t1\r\n",
      "chrM:25\t1\r\n",
      "chrM:26\t1\r\n",
      "chrM:27\t1\r\n",
      "chrM:28\t1\r\n",
      "chrM:29\t1\r\n",
      "chrM:30\t1\r\n",
      "chrM:31\t1\r\n",
      "chrM:32\t1\r\n",
      "chrM:33\t1\r\n",
      "chrM:34\t1\r\n",
      "chrM:35\t1\r\n",
      "chrM:36\t1\r\n",
      "chrM:37\t1\r\n",
      "chrM:38\t1\r\n",
      "chrM:39\t1\r\n",
      "chrM:40\t1\r\n",
      "chrM:41\t1\r\n",
      "chrM:42\t1\r\n",
      "chrM:43\t1\r\n",
      "chrM:44\t1\r\n",
      "chrM:45\t1\r\n",
      "chrM:46\t1\r\n",
      "chrM:47\t1\r\n",
      "chrM:48\t1\r\n",
      "chrM:49\t1\r\n",
      "chrM:50\t1\r\n",
      "chrM:51\t1\r\n",
      "chrM:52\t1\r\n",
      "chrM:53\t1\r\n",
      "chrM:54\t1\r\n",
      "chrM:55\t1\r\n",
      "chrM:56\t1\r\n",
      "chrM:57\t1\r\n",
      "chrM:58\t1\r\n",
      "chrM:59\t1\r\n",
      "chrM:60\t1\r\n",
      "chrM:61\t1\r\n",
      "chrM:62\t1\r\n",
      "chrM:63\t1\r\n",
      "chrM:64\t1\r\n",
      "chrM:65\t1\r\n",
      "chrM:66\t1\r\n",
      "chrM:67\t1\r\n",
      "chrM:68\t1\r\n",
      "chrM:69\t1\r\n",
      "chrM:70\t1\r\n",
      "chrM:71\t1\r\n",
      "chrM:72\t1\r\n",
      "chrM:73\t1\r\n",
      "chrM:74\t1\r\n",
      "chrM:75\t1\r\n",
      "chrM:76\t1\r\n",
      "chrM:77\t1\r\n",
      "chrM:78\t1\r\n",
      "chrM:79\t1\r\n",
      "chrM:80\t1\r\n",
      "chrM:81\t1\r\n",
      "chrM:82\t1\r\n",
      "chrM:83\t1\r\n",
      "chrM:84\t1\r\n",
      "chrM:85\t1\r\n",
      "chrM:86\t1\r\n",
      "chrM:87\t1\r\n",
      "chrM:88\t1\r\n",
      "chrM:89\t1\r\n",
      "chrM:90\t1\r\n",
      "chrM:91\t1\r\n",
      "chrM:92\t1\r\n",
      "chrM:93\t1\r\n"
     ]
    }
   ],
   "source": [
    "! head -n 100 $myfile | python mapper.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Shuffle step \n",
    "\n",
    "<br><big>\n",
    "A lot happens, transparent to the developer\n",
    "</big>\n",
    "\n",
    "* Mappers’s output is transformed and distributed to the reducers\n",
    "* All key/value pairs are sorted before sent to reducer function\n",
    "* Pairs sharing the same key are sent to the same reducer\n",
    "* If you encounter a key that is different from the last key you processed\n",
    "    - *you know that previous key will never appear again*\n",
    "* If your keys are all the same\n",
    "    - only use one reducer and gain no parallelization\n",
    "    - come up with a more unique key if this happens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Reducer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "TAB = \"\\t\"\n",
    "SEP = ':'\n",
    "import sys\n",
    "last_value = \"\"\n",
    "value_count = 1\n",
    "for line in sys.stdin:\n",
    "    value, count = line.strip().split(TAB)\n",
    "    # if this is the first iteration\n",
    "    if not last_value:\n",
    "        last_value = value\n",
    "    # if they're the same, log it\n",
    "    if value == last_value:\n",
    "        value_count += int(count)\n",
    "    else:\n",
    "        # state change\n",
    "        try: \n",
    "            print(TAB.join([last_value, str(value_count)]))\n",
    "        except:\n",
    "            pass\n",
    "        last_value = value\n",
    "        value_count = 1\n",
    "# LAST ONE after all records have been received\n",
    "print(TAB.join([last_value, str(value_count)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr1:10000\t3\n",
      "chr1:10001\t2\n",
      "chr1:10002\t2\n",
      "chr1:10003\t2\n",
      "chr1:10004\t2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t0m3.880s\n",
      "user\t0m3.800s\n",
      "sys\t0m0.070s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# needs ~ 5 seconds for running\n",
    "time head -n 10000 $myfile | python mapper.py | sort | python reducer.py | head -n 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t2m24.110s\n",
      "user\t2m20.610s\n",
      "sys\t0m2.050s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "time cat $myfile | python mapper.py | sort | python reducer.py > out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chr21:11181667\t185\n",
      "chr21:11181668\t185\n",
      "chr21:11181669\t185\n",
      "chr7:151970834\t185\n",
      "chr7:151970867\t185\n"
     ]
    }
   ],
   "source": [
    "! grep \"\\s185\" out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Write a mapper and a reducer in python to group words of \"The Prince\" based on their length.\n",
    "\n",
    "The book is available at the following path: `/data/lectures/data/books/prince.txt`\n",
    "\n",
    "Find out how many are longer than ten letters or shorter than five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Switching to real Hadoop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "A working python code tested on pipes **should work** with Hadoop Streaming\n",
    "</big>\n",
    "\n",
    "* To make this happen we need to handle copy of input and output files inside the Hadoop FS\n",
    "* Also the job tracker logs will be found inside HDFS\n",
    "* We are going to use bash scripting inside the notebook to make our workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "HDFS commands to interact with Hadoop file system use the same syntax:\n",
    "\n",
    "```\n",
    "hdfs dfs -command\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`command` are like bash commands for file\n",
    "\n",
    "e.g.\n",
    "\n",
    "```\n",
    "hadoop fs -mkdir hdfs:///dir\n",
    "hadoop fs -put file_on_host hdfs:///path/to/file\n",
    "hadoop fs -ls\n",
    "```\n",
    "\n",
    "<small>\n",
    "Note: we have seen this in action with the Java example\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<big>\n",
    "Hadoop Streaming needs “binaries” to execute\n",
    "</big>\n",
    "\n",
    "You need to specify interpreter at the beginning of your scripts:\n",
    "```\n",
    "#!/usr/bin/env python\n",
    "```\n",
    "\n",
    "Make also the script executables:\n",
    "```\n",
    "chmod +x hs*.py\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! chmod +x mapper.py reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/usr/local/hadoop/share/hadoop/tools/lib/hadoop-streaming-2.6.0.jar'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%env HADOOP_STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: $HADOOP_PREFIX/bin/hadoop jar hadoop-streaming.jar [options]\n",
      "Options:\n",
      "  dumptb <glob-pattern> Dumps all files that match the given pattern to \n",
      "                        standard output as typed bytes.\n",
      "  loadtb <path> Reads typed bytes from standard input and stores them in\n",
      "                a sequence file in the specified path\n",
      "  [streamjob] <args> Runs streaming job with given arguments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No Arguments Given!\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Launch streaming\n",
    "hadoop jar $HADOOP_STREAMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted myinput\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16/03/15 17:04:11 INFO fs.TrashPolicyDefault: Namenode trash configuration: Deletion interval = 0 minutes, Emptier interval = 0 minutes.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Preprocess with HDFS\n",
    "hdfs dfs -rm -r -f myinput\n",
    "hdfs dfs -mkdir myinput\n",
    "# Save one file inside\n",
    "file=\"/tmp/ngs.sam\"\n",
    "hdfs dfs -put $file myinput/file01\n",
    "# Remove output or Hadoop will give error if existing\n",
    "hdfs dfs -rm -r -f myoutput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Final launch via bash command for using Hadoop streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "%%bash \n",
    "# A real Hadoop Streaming run\n",
    "time hadoop jar $HADOOP_STREAMING \\\n",
    "    -D mapreduce.job.mapper=12 -D mapreduce.job.reducers=4  \\\n",
    "    -files mapper.py,reducer.py \\\n",
    "    -input myinput -output myoutput \\\n",
    "    -mapper mapper.py -reducer reducer.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<small>\n",
    "**Note 1**:\n",
    "\n",
    "if this comand takes minutes, you may go to see what is happening in your Hadoop JobTracker, if you have it, e.g.\n",
    "http://localhost:8088/cluster\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "**Note 2**:\n",
    "\n",
    "this command cannot be executed from the cloud version of the notebooks, as the port is not opened\n",
    "</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Hadoop streaming is **difficult to debug**.\n",
    "Just like real Java Hadoop.\n",
    "\n",
    "If you did a typical setup mistake, you may end receiving unrelated errors stacktrace from the Java virtual machine.\n",
    "\n",
    "So before googling those stacktrace, make sure that:\n",
    "\n",
    "* Python files (mapper and reducer) exists\n",
    "* They are provided inside the main bash command also as **files** list\n",
    "* They are executables and contain as first line the hashbang\n",
    "* Your input directory exists on HDFS\n",
    "* Files inside your input directory are not corrupted\n",
    "    - e.g. bad decompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUT: Check directory\n",
    "! hdfs dfs -ls myoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# OUTPUT:  Copy file and go see it\n",
    "! rm -rf hs.*.txt && hdfs dfs -get myoutput/part-00000 hs.out.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "! head hs.out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise\n",
    "\n",
    "Run your previously written python Mapper/Reducer with Hadoop Streaming.\n",
    "\n",
    "(*Good luck*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final thoughts on Hadoop Streaming "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* Provides options to write MapReduce jobs in other languages\n",
    "* Even executables can be used to work as a MapReduce job\n",
    "* One of the best examples of flexibility available to MapReduce\n",
    "* Fast\n",
    "* Simpler than Java\n",
    "* Also close to the original standard Java API Hadoop power\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Where it really works\n",
    "\n",
    "* When the developer do not have knowhow of Java \n",
    "* Write Mapper/Reducer in any scripting language "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Disadvantages\n",
    "\n",
    "* Force scripts in a Java VM\n",
    "    - Although almost free overhead\n",
    "* The program/executable have to take input from STDIN \n",
    "    - and produce output at STDOUT\n",
    "* Restrictions on the input/output formats\n",
    "    - Does not take care of input and output file and directory preparation\n",
    "    - User have to implement hdfs commands “hand-made”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Where it falls short\n",
    "\n",
    "* No pythonic way to work the MapReduce code\n",
    "\n",
    "(Because it was not written specifically for python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap \n",
    "\n",
    "* Hadoop streaming handles Hadoop in almost a classic manner\n",
    "* Wrap any executable (and script)\n",
    "    - Also python scripts\n",
    "* Runnable on a cluster using a non-interactive, all-encapsulated job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# End of Chapter"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
