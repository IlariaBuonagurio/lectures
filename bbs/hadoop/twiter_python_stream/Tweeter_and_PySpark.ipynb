{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare spark \n",
    "I am using **HiveContext** that need an embedded database *stored on Current Working Directory*. Because of that you have to **shutdown others notebooks** that use HiveContext."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext\n",
    "\n",
    "conf = SparkConf().setAppName(\"Prova Streaming\").setMaster(\"local[*]\")\n",
    "sc = SparkContext(conf = conf)\n",
    "sqlCtx = HiveContext(sc)\n",
    "print ( \"Started spark version %s\" % (sc.version) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare chart environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install tweet library tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "! pip install tweepy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Prepare python code for Tweeter streaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buffered Tweet Receiver\n",
    "This class receive message from tweeter and memorize them in a buffer.\n",
    "Using the **retrieve_messages** method, a client, class, can get a DataFrame with message information. This operation also *flush the buffered messages*\n",
    "\n",
    "This class has also some display capability; it show:\n",
    " - The number of messages in the buffer\n",
    " - Full dump of the last message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tweepy.streaming import StreamListener\n",
    "from ipywidgets import IntProgress\n",
    "from ipywidgets import Textarea\n",
    "from IPython import display\n",
    "from random import randint\n",
    "\n",
    "# See also http://adilmoujahid.com/posts/2014/07/twitter-analytics/\n",
    "class BufferedTweeterMessageReceiver(StreamListener):\n",
    "    \n",
    "    def __init__(self):\n",
    "        StreamListener.__init__(self) # - Call superclass constructor\n",
    "        self._messages = [] # - Initially empty buffer\n",
    "        self._init_display() \n",
    "    \n",
    "    # - Create some widget\n",
    "    def _init_display(self):\n",
    "        # - show how many messages we have in the buffer\n",
    "        self._progressbarr = IntProgress(description='Arrived Messages', min=0, max=1000)\n",
    "        display.display(self._progressbarr)\n",
    "        # - show last message\n",
    "        self._text = Textarea(description='msg:')\n",
    "        display.display(self._text)\n",
    "    \n",
    "    # - Called by tweepy library: here we receive messages\n",
    "    def on_data(self, data):\n",
    "        self._progressbarr.value = len(self._messages)\n",
    "        self._text.value = data\n",
    "        self._messages.append(data)\n",
    "        return True\n",
    "    \n",
    "    # - Called by tweepy library: here we receive messages\n",
    "    def on_error(self, status):\n",
    "        print(status)\n",
    "    \n",
    "    # - Called from the streaming application to receive messages\n",
    "    def retrieve_messages(self):\n",
    "        messages = self._messages\n",
    "        self._messages = []\n",
    "        \n",
    "        # messages_DF = sqlCtx.read.json( sc.parallelize(messages))\n",
    "        # - I can't use the line above for an issue with python to java string convertion\n",
    "        #   the temporary file is only one. So I can't run more applications concurrently\n",
    "        fileName = 'tmp.json'\n",
    "        with open(fileName, 'w') as data_file:    \n",
    "            for msg in messages:\n",
    "                data_file.write(msg)\n",
    "        messages_DF = sqlCtx.read.json(fileName)\n",
    "        return messages_DF\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Loop For streeming analysis\n",
    "This class \n",
    " - initialyze receiver and credential\n",
    " - start the tweeter connection *stream*\n",
    " - Enter in a loop of:\n",
    "     * receive chunk of data\n",
    "     * analyze received chunk of data\n",
    "     * display something\n",
    " - Eventually stop the *connection stream* **and** the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from threading import Timer\n",
    "from tweepy import OAuthHandler, Stream\n",
    "from ipywidgets import Textarea, Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import io\n",
    "\n",
    "# - Skeleton for streaming\n",
    "#   Keywords and period are configurable only from the constructor. \n",
    "#   We could do better.\n",
    "class TweeterDataReceiver(object):\n",
    "    \n",
    "    def __init__(self, keywords, period=10):\n",
    "        # load credential\n",
    "        self._init_credential()\n",
    "        # init message receiver before my widgets so the widgets of \n",
    "        # message receiver are inited before mine.\n",
    "        self._tweeter_msg_rcv = BufferedTweeterMessageReceiver()\n",
    "        self._init_widgets()\n",
    "        \n",
    "        self._keywords = keywords\n",
    "        self._period = period\n",
    "        self._stream = None\n",
    "        self._stop = False\n",
    "        \n",
    "    def _init_widgets(self):\n",
    "        # - Show analysis results history ...\n",
    "        self._output = Textarea(description='Histories')\n",
    "        display.display(self._output)\n",
    "        # ... and charts\n",
    "        self._img = Image(description='chat', width=480)\n",
    "        display.display(self._img)\n",
    "    \n",
    "    \n",
    "    # - see http://adilmoujahid.com/posts/2014/07/twitter-analytics/ Step 1\n",
    "    def _init_credential(self):\n",
    "        with open('credentials.json') as data_file:    \n",
    "            credentials = json.load(data_file)\n",
    "        self._auth = OAuthHandler( credentials['consumer_key'], credentials['consumer_secret'] )\n",
    "        self._auth.set_access_token( credentials['access_token'], credentials['access_token_secret'] )\n",
    "    \n",
    "    \n",
    "    # - Initialize the tweepy stream and start the loop\n",
    "    def start(self):\n",
    "        if self._stream:\n",
    "            self.stop()\n",
    "        self._data_history = {}\n",
    "        self._chunk_counter = 0\n",
    "        self._stream = Stream(self._auth, self._tweeter_msg_rcv)\n",
    "        self._stream.filter(track=self._keywords, async=True)\n",
    "        self._loop()\n",
    "    \n",
    "    # - Disconnect the tweepy stream and tell the toop to end\n",
    "    def stop(self):\n",
    "        if self._stream:\n",
    "            self._stream.disconnect()\n",
    "            self._stream = None\n",
    "        self._stop = True\n",
    "    \n",
    "    # - Main loop \n",
    "    def _loop(self):\n",
    "        if not self._stop:\n",
    "            self._oneStep()\n",
    "            def nextStep():\n",
    "                self._loop()\n",
    "            Timer(self._period, nextStep, ()).start() \n",
    "        else:\n",
    "            print(\"Stop\")\n",
    "    \n",
    "    \n",
    "    # - This method describe the flow of each iteration\n",
    "    def _oneStep(self):\n",
    "        # Read the messages ...\n",
    "        chunk_messages_dataframe = self._tweeter_msg_rcv.retrieve_messages()\n",
    "        # ... compute some statistic ...\n",
    "        chunk_analysis_result = self.analyze_one_chunk(chunk_messages_dataframe)\n",
    "        # ... memeorize the result together with previous ones ...\n",
    "        self._merge_analysis_history(chunk_analysis_result)\n",
    "        # ... update widgets\n",
    "        self.display_history(self._data_history)\n",
    "    \n",
    "    \n",
    "    # - For each key in the dictionary chunk_analysis_result read the value and \n",
    "    #   append it in the same key of self._data_history\n",
    "    def _merge_analysis_history(self, chunk_analysis_result):\n",
    "        # - for each result information ...\n",
    "        for key in chunk_analysis_result:\n",
    "            if key not in self._data_history:\n",
    "                self._data_history[key] = [0] * self._chunk_counter\n",
    "            # ... add it in the right place in history\n",
    "            value = chunk_analysis_result[key]\n",
    "            self._data_history[key].append( value )\n",
    "        \n",
    "        # - Add necessary 0 to keep all history aligned\n",
    "        for key in self._data_history:\n",
    "            if len(self._data_history[key]) <= self._chunk_counter:\n",
    "                self._data_history[key].append( 0 )\n",
    "        \n",
    "        # - Update history length\n",
    "        self._chunk_counter += 1\n",
    "    \n",
    "    \n",
    "    # - Actually only count the number of messages\n",
    "    def analyze_one_chunk(self, chunk_DF):\n",
    "        return {\"n\" : chunk_DF.count()}\n",
    "    \n",
    "    # - Write data into a text area and draw chart\n",
    "    def display_history(self, data_history):\n",
    "        \n",
    "        # write log\n",
    "        if len(self._output.value) > 0:\n",
    "            self._output.value += \"\\n\"\n",
    "        self._output.value += json.dumps(data_history)\n",
    "        self._output.scroll_to_bottom()\n",
    "        \n",
    "        # draw chart\n",
    "        for key in data_history:\n",
    "            plt.plot(data_history[key], label=key)\n",
    "        plt.legend()\n",
    "        \n",
    "        # put che chart into an Image widget\n",
    "        buf = io.BytesIO()\n",
    "        plt.savefig(buf, format='png')\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "        buf.seek(0)\n",
    "        self._img.value = buf.read(100000)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app1 = TweeterDataReceiver(['scala', 'python'])\n",
    "app1.start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app1.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now we develop some analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: List languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LanguageAnalyzer(TweeterDataReceiver):\n",
    "    \n",
    "    def __init__(self, keywords, period=5):\n",
    "        TweeterDataReceiver.__init__(self, keywords, period)\n",
    "        \n",
    "    \n",
    "    def analyze_one_chunk(self, messages_DF):\n",
    "        if messages_DF.count() > 0:\n",
    "            # TODO: get the list of languages\n",
    "        else :\n",
    "            return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app2 = LanguageAnalyzer(['trump'], period=1)\n",
    "app2.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app2.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: Look for keyword inside message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function used during elaboration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    if l != None:\n",
    "        return # TODO flatten a list of lists into a list\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def contains(l, w):\n",
    "    # TODO return 1 if w is an element of l; 0 otherwise\n",
    "\n",
    "sqlCtx.registerFunction(\"MY_flatten\", lambda l: flatten(l) )\n",
    "sqlCtx.registerFunction(\"MY_contains\", lambda l, w: contains(l, w) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TweetAnalyzer(TweeterDataReceiver):\n",
    "    \n",
    "    def __init__(self, keywords, period=10):\n",
    "        TweeterDataReceiver.__init__(self, keywords, period)\n",
    "        \n",
    "    \n",
    "    def analyze_one_chunk(self, messages_DF):\n",
    "        if messages_DF.count() > 0:\n",
    "            # TODO: follow the esercitation\n",
    "        else :\n",
    "            return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "app3 = TweetAnalyzer(['trump', 'curry'], period=10)\n",
    "app3.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "app3.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usefull for development"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_DF = app1._tweeter_msg_rcv.retrieve_messages()\n",
    "test_DF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "messages_DF = test_DF\n",
    "messages_DF.printSchema()\n",
    "result_DF = messages_DF.select(\"id\")\n",
    "result_DF.show()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
