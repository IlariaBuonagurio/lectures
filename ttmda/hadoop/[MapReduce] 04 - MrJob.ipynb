{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A more pythonic MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With Hadoop Streaming we switched MapReduce from Java to Python.\n",
    "\n",
    "How could we improve some more? \n",
    "\n",
    "What problems do we deal with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have to directly deal with HDFS\n",
    "* move input files\n",
    "* recover outputs\n",
    "* human make mistakes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Not easy debugging\n",
    "\n",
    "* logs via jobtracker\n",
    "* errors are Java stacktrace, often unrelated with the real problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We have to write two different files\n",
    "* one for the mapper\n",
    "* one for the reducer\n",
    "* not a **module**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Is there a Python part of the language that can help representing a MapReduce task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# A python class\n",
    "\n",
    "class myclass(object):\n",
    "    \n",
    "    a_property = 42\n",
    "    \n",
    "    def a_method(self):\n",
    "        pass\n",
    "    def another_method(self, var):\n",
    "        print(var)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create instance of our class\n",
    "instance = myclass()\n",
    "# Use it\n",
    "instance.a_method()\n",
    "instance.another_method(\"test\")\n",
    "instance.a_property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class MapReduce(object):\n",
    "    \"\"\" A MapReduce class prototype \"\"\"\n",
    "    \n",
    "    def mapper(self, line):\n",
    "        pass\n",
    "    def reducer(self, sorted_line):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MRJob \n",
    "A more pythonic MapReduce library from Yelp\n",
    "\n",
    "<img src='https://avatars1.githubusercontent.com/u/49071?v=3&s=400' width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> “Easiest route to Python programs that run on Hadoop”\n",
    "\n",
    "Install with: \n",
    "```bash\n",
    "pip install mrjob\n",
    "```\n",
    "\n",
    "**Running modes**\n",
    "* Test your code locally without installing Hadoop \n",
    "* or run it on a cluster of your choice!\n",
    "    - Integrates with Amazon **Elastic MapReduce** (EMR)\n",
    "    - same code with local, Hadoop, EMR\n",
    "    - easy to run your job in the cloud as on your laptop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### How does MrJob work?\n",
    "\n",
    "Python module built on top of Hadoop Streaming\n",
    "jar opens a subprocess to your code\n",
    "sends it input via stdin\n",
    "gathers results via stdout.\n",
    "Wrap HDFS pre and post processing if hadoop exists\n",
    "a consistent interface across every environment it supports\n",
    "automatically serializes/deserializes data flow out of each task \n",
    "JSON: json.loads() and json.dumps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting hands dirty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A job is defined by a class extended from MRJob package\n",
    "Contains methods that define the steps of a Hadoop job\n",
    "A “step” consists of a mapper, a combiner, and a reducer. \n",
    "All of those  are optional, though you must have at least on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myjob(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        pass\n",
    "    def combiner(self, key, values):\n",
    "        pass\n",
    "    def reducer(self, key, values):\n",
    "        pass\n",
    "    def steps(self):\n",
    "        return [ MRStep(mapper=self.mapper, … ), … ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper\n",
    "\n",
    "The mapper() method takes a key and a value as args\n",
    "E.g. key is ignored and a single line of text input is the value\n",
    "Yields as many key-value pairs as it likes\n",
    "Warning: yield != return\n",
    "yield return a generator, the one you usually use with \n",
    "print i; for i in generator\n",
    "Example\n",
    "```python\n",
    "def mygen():\n",
    "for i in range(1,10):\n",
    "# THIS IS WHAT HAPPENS INSIDE MAPPER\n",
    "yield i, “value” \n",
    "\n",
    "for key, value in mygen():\n",
    "print key, value\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reducer\n",
    "\n",
    "The reduce() method takes a key and an iterator of values\n",
    "Also yields as many key-value pairs as it likes\n",
    "E.g. it sums the values for each key\n",
    "Represent the  numbers of characters, words, and lines in the initial input\n",
    "\n",
    "Example\n",
    "```python\n",
    "def mygen():\n",
    "for i in range(1,10):\n",
    "yield i, “value” \n",
    "\n",
    "for key, value in mygen():\n",
    "# THIS IS WHAT HAPPENS INSIDE A REDUCER\n",
    "print key, value\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%writefile \n",
    "from mrjob.job import MRJob\n",
    "class MRWordCount(MRJob):\n",
    "\n",
    "    def mapper(self, key, line):\n",
    "        for word in line.split(' '):\n",
    "             yield word.lower(),1\n",
    "\n",
    "    def reducer(self, word, occurrences):\n",
    "        yield word, sum(occurrences)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    MRWordCount.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input\n",
    "\n",
    "By default, output will be written to stdout.\n",
    "$ python my_job.py input.txt\n",
    "\n",
    "You can pass input via stdin\n",
    "but be aware that mrjob will just dump it to a file first:\n",
    "$ python my_job.py < input.txt\n",
    "\n",
    "You can pass multiple input files, mixed with stdin (using the – character)\n",
    "$ python my_job.py input1.txt input2.txt - < input3.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Download compressed NGS data from a link\n",
    "wget -q \"http://bit.ly/ngs_sample_data\" -O $myfile.bz2 && echo \"downloaded\"\n",
    "# Decompress the file\n",
    "bunzip2 $myfile.bz2 && echo \"decompressed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! python word_count.py data/txt/2261.txt.utf-8 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mrjob can be configured to run different steps\n",
    "\n",
    "for each step you can specify which part has to be executed\n",
    "and the method to use within the class you wrote\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def steps(self):\n",
    "    return [\n",
    "        MRStep(\n",
    "            mapper=self.mapper_get_words,\n",
    "            combiner=self.combiner_count_words,\n",
    "            reducer=self.reducer_count_words),\n",
    "        MRStep(reducer=self.reducer_find_max_word)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, mrjob will run your job on your local (normal) environment) in a single Python process \n",
    "\n",
    "You change the way the job is run with the `-r/--runner` option:\n",
    "\n",
    "```\n",
    "-r inline, -r local, -r hadoop, or -r emr\n",
    "```\n",
    "\n",
    "Use also `--verbose` option to show all the steps"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
